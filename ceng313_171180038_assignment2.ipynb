{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN (K-Nearest Neighbors) Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name Surname: Ayşe Karataş No:171180038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "#was used for write train_test_split\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "iris_dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Distance With Euclidean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euclidean(test_line, train_line):\n",
    "    inside_sqrt = 0\n",
    "    for i in range(len(test_line)):\n",
    "        inside_sqrt += math.pow((test_line[i] - train_line[i]),2)\n",
    "    result = math.sqrt(inside_sqrt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Method by comparing with \"np.linalg.norm(point1 - point2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Method Result: 2.23606797749979\n",
      "Ready Method Result: 2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "point1 = np.array((1, 2, 3)) \n",
    "point2 = np.array((1, 1, 1)) \n",
    "\n",
    "print(\"My Method Result: \" + str(Euclidean(point1, point2)))\n",
    "print(\"Ready Method Result: \" + str(np.linalg.norm(point1 - point2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: While writing this section, I used the following Euclidean formula.\n",
    "\n",
    "{\\displaystyle {\\begin{aligned}d(\\mathbf {p} ,\\mathbf {q} )=d(\\mathbf {q} ,\\mathbf {p} )&={\\sqrt {(q_{1}-p_{1})^{2}+(q_{2}-p_{2})^{2}+\\cdots +(q_{n}-p_{n})^{2}}}\\\\[8pt]&={\\sqrt {\\sum _{i=1}^{n}(q_{i}-p_{i})^{2}}}.\\end{aligned}}}\n",
    "\n",
    "Source: https://www.geeksforgeeks.org/calculate-the-euclidean-distance-using-numpy/\n",
    "\n",
    "https://www.datasciencearth.com/veri-madenciligi-ve-oklid-uzakligi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset (Training Set & Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomState method / The array is shuffled\n",
    "def sort_random_state(value, arr):\n",
    "    rs = RandomState(value)\n",
    "    return rs.permutation(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting array to test and train set\n",
    "def splitting(arr, test_size, random_state):\n",
    "    arr_new = sort_random_state(random_state, arr)\n",
    "    arr_test = arr_new[:round(len(arr)*test_size)]\n",
    "    arr_train = arr_new[round(len(arr)*test_size) : len(arr)]\n",
    "    return arr_train, arr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting x and y to test and train set\n",
    "def train_test_splitt(x, y, test_size=0.3, random_state=None):\n",
    "    x_train, x_test =  splitting(x, test_size, random_state)\n",
    "    y_train, y_test =  splitting(y, test_size, random_state)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Method by comparing with \"sklearn.model_selection.train_test_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Function: \n",
      "Xx_train: \n",
      "[[4 5]\n",
      " [0 1]\n",
      " [6 7]]\n",
      "Xx_test: \n",
      "[[2 3]\n",
      " [8 9]]\n",
      "yy_train: \n",
      "[2 0 3]\n",
      "yy_test: \n",
      "[1 4]\n"
     ]
    }
   ],
   "source": [
    "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
    "Xx_train, Xx_test, yy_train, yy_test = train_test_splitt(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"My Function: \")\n",
    "print(\"Xx_train: \")\n",
    "print(Xx_train)\n",
    "print(\"Xx_test: \")\n",
    "print(Xx_test)\n",
    "print(\"yy_train: \")\n",
    "print(yy_train)\n",
    "print(\"yy_test: \")\n",
    "print(yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready Function: \n",
      "X_train: \n",
      "[[4 5]\n",
      " [0 1]\n",
      " [6 7]]\n",
      "X_test: \n",
      "[[2 3]\n",
      " [8 9]]\n",
      "y_train: \n",
      "[2, 0, 3]\n",
      "y_test: \n",
      "[1, 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"Ready Function: \")\n",
    "print(\"X_train: \")\n",
    "print(X_train)\n",
    "print(\"X_test: \")\n",
    "print(X_test)\n",
    "print(\"y_train: \")\n",
    "print(y_train)\n",
    "print(\"y_test: \")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: When I first read the assignment document, I did not see I can use scikit learn library for this method. After writing this method I realized I don't need to write. So, I wanted to include it in assignment because it works correctly.\n",
    "\n",
    "In this section, I noticed that the elements in the test and train set were randomly selected, but I noticed that each time they gave the same result.\n",
    "When I researched, I found out that it depends on \"random_state\". This feature in the scikit learn library was based on numpy.random.RandomState().\n",
    "\n",
    "Sources: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier Class (Classification & Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNeighborsClassifierr:\n",
    "    #constructor\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.k = n_neighbors\n",
    "    \n",
    "    #combined into a array / train_set\n",
    "    def fit(self, data, target):\n",
    "        #I combine in a array / horizontal combine\n",
    "        #I couldn't use hstack or concatenate because arrays must the same size\n",
    "        df_train = pd.DataFrame(data)\n",
    "        df_train[\"target\"] = target\n",
    "        self.train_set = np.array(df_train)\n",
    "    \n",
    "    #all predictions combined\n",
    "    def predict(self, test):\n",
    "        result = []\n",
    "        for t in test:\n",
    "            result.append(self.find_neighbors_and_pred(t))\n",
    "        return np.array(result)\n",
    "    \n",
    "    #finding neighbors of a test point and its class is predicted\n",
    "    def find_neighbors_and_pred(self, test_data):\n",
    "        distances = []\n",
    "        for i in range(len(self.train_set)):\n",
    "            distances.append(Euclidean(test_data, self.train_set[i,:]))\n",
    "            \n",
    "        df_combine_dist = pd.DataFrame(self.train_set)\n",
    "        df_combine_dist[\"distances\"] = np.array(distances)\n",
    "        combine_dist = np. array(df_combine_dist)\n",
    "        \n",
    "        #sorting according to distances / last index\n",
    "        sorted_combine_dist = combine_dist[combine_dist[: ,(len(combine_dist[0])-1)].argsort()]\n",
    "        result = sorted_combine_dist[:self.k,:]\n",
    "        \n",
    "        # there aren't mode in numpy so i use DataFrame with pandas\n",
    "        df_result = pd.DataFrame(result[: ,(len(result[0])-2)])\n",
    "        \n",
    "        # was used mean() in case of more than one mode() result\n",
    "        # was used int() for get integer\n",
    "        return int(np.array(df_result.mode()).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Method according to \"sklearn.neighbors.KNeighborsClassifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Example Used From Lesson Slide (ceng313_week8_classification): \n",
      "My Function: \n",
      "Prediction: [0]\n",
      "Predicted target name: ['setosa']\n"
     ]
    }
   ],
   "source": [
    "print(\"This Example Used From Lesson Slide (ceng313_week8_classification): \")\n",
    "print(\"My Function: \")\n",
    "Xx_train, Xx_test, yy_train, yy_test=train_test_splitt(iris_dataset['data'], iris_dataset['target'],test_size=0.25, random_state=0)\n",
    "\n",
    "my_knn = KNeighborsClassifierr(1)\n",
    "my_knn.fit(Xx_train, yy_train)\n",
    "\n",
    "Xx_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "\n",
    "prediction = my_knn.predict(Xx_new)\n",
    "print(\"Prediction: {}\".format(prediction))\n",
    "print(\"Predicted target name: {}\".format(iris_dataset['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Sklearn Library: \n",
      "Prediction: [0]\n",
      "Predicted target name: ['setosa']\n"
     ]
    }
   ],
   "source": [
    "print(\"With Sklearn Library: \")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "\n",
    "prediction = knn.predict(X_new)\n",
    "print(\"Prediction: {}\".format(prediction))\n",
    "print(\"Predicted target name: {}\".format(\n",
    "iris_dataset['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Function: \n",
      "Test set predictions:\n",
      " [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"My Function: \")\n",
    "yy_pred = my_knn.predict(Xx_test)\n",
    "print(\"Test set predictions:\\n {}\".format(yy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit Result: \n",
      "Test set predictions:\n",
      " [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Scikit Result: \")\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: KNeighborsClassifierr class can work all positive integer parameters. For example if k is 1 or 2 or 3 or 4 or 5 etc., KNeighborsClassifierr can work. I just showed 1 neighbor example that was in the lesson, but It can work k is 3 or 5.\n",
    "\n",
    "In fit method, I combined all arrays into train_set array. So, I thought I could make class prediction easier.\n",
    "\n",
    "In find_neighbors_and_pred method, I find a test point class prediction according to Euclidean function I wrote. Firstly, I found all distances and I combined train_set array. So, When I sort according to distances, I also get this neighbors classes. Then, I take neighbors' class mode , so I get most found class. I took the aritmatic mean and converted it to an integer, just in case there is more than one mode value.\n",
    "\n",
    "In prediction method, I combined all test points predictions in a array.\n",
    "\n",
    "Sources: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My methods test set score: 0.97\n",
      "Must be test set score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"My methods test set score: {:.2f}\".format(np.mean(yy_pred == yy_test)))\n",
    "print(\"Must be test set score: {:.2f}\".format(np.mean(y_pred == y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
